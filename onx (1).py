# -*- coding: utf-8 -*-
"""ONX.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NrQhfjai-skxleD6kxZZWe7Tx6xgw618
"""

!pip install onnx skl2onnx onnxruntime

# -*- coding: utf-8 -*-
"""ONNX Model Conversion and Testing
This script trains a machine learning model in Python, converts it to ONNX format, and tests the ONNX model for inference.
"""

# Load sample data using `pandas` and `scikit-learn`
import pandas as pd  # `pandas` is used for handling data in tabular form (like Excel tables)
from sklearn.datasets import load_iris  # Load a built-in dataset (Iris dataset) from scikit-learn
import numpy as np

# Step 1: Load and Prepare the Iris Dataset
# Iris dataset contains information about 3 types of flowers (setosa, versicolor, virginica)
iris = load_iris()  # Load the Iris dataset from scikit-learn's built-in datasets

# Create a DataFrame from the iris data (structured like a table)
# `iris.data` contains the features (like petal length, sepal width, etc.)
df = pd.DataFrame(iris.data, columns=iris.feature_names)  # Add column names from the dataset

# Add a new column 'species' to the DataFrame, which contains the target values (flower types)
df['species'] = iris.target  # Target values are 0 (setosa), 1 (versicolor), 2 (virginica)

# Print the first 5 rows of the DataFrame to see the structure of the dataset
print("Dataset preview:")
print(df.head())  # `.head()` shows the first 5 rows of the DataFrame

# Step 2: Preprocess the Data (Scaling and Splitting)
from sklearn.model_selection import train_test_split  # Used to split the dataset into training and testing parts
from sklearn.preprocessing import StandardScaler  # Used to scale (normalize) the feature values

# Split the dataset into training and testing sets (70% train, 30% test)
# `X_train` and `X_test` will contain feature values (petal/sepal measurements)
# `y_train` and `y_test` will contain target labels (flower species)
X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df['species'], test_size=0.3, random_state=42)

# Apply Standard Scaling to standardize feature values
# Scaling is important because it makes sure that all feature values are on a similar scale (mean = 0, std = 1)
scaler = StandardScaler().fit(X_train)  # Calculate the scaling parameters (mean and std) on the training data
X_train = scaler.transform(X_train)  # Apply scaling to the training data
X_test = scaler.transform(X_test)  # Apply the same scaling to the test data (based on training parameters)

# Step 3: Train a Simple Machine Learning Model
from sklearn.linear_model import LogisticRegression  # Import the Logistic Regression algorithm

# Initialize the Logistic Regression model
# Logistic Regression is a simple classification algorithm that works well on small datasets
model = LogisticRegression()  # Create an instance of the Logistic Regression model

# Train (fit) the model using the training data
# `X_train` contains the scaled feature values, and `y_train` contains the corresponding target labels
model.fit(X_train, y_train)  # The model learns patterns in the data during this step

# Evaluate the model by calculating its accuracy on the test set
accuracy = model.score(X_test, y_test)  # This compares predicted labels with actual labels in `y_test`
print(f"Model Accuracy: {accuracy:.2f}")  # Print the accuracy (percentage of correct predictions)

# Step 4: Convert the Trained Model to ONNX Format
import onnx  # Main library for handling ONNX models
from skl2onnx import convert_sklearn  # Tool to convert scikit-learn models to ONNX format
from skl2onnx.common.data_types import FloatTensorType  # Specify input data type for ONNX model

# Define the input type for the ONNX model
# Here, we specify that the model will accept input data in the form of a tensor (array) with floating-point values
initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]  # None means any batch size

# Convert the trained scikit-learn Logistic Regression model to ONNX format
onnx_model = convert_sklearn(model, initial_types=initial_type)

# Save the ONNX model to a file so we can load it later
with open("logistic_regression.onnx", "wb") as f:
    f.write(onnx_model.SerializeToString())  # Save the ONNX model to disk

print("Model has been successfully converted to ONNX format and saved as 'logistic_regression.onnx'.")

# Step 5: Load and Test the ONNX Model for Inference
import onnxruntime as ort  # ONNX Runtime is used to load and run the ONNX model

# Load the ONNX model from the file
session = ort.InferenceSession("logistic_regression.onnx")  # Create an inference session for the ONNX model

# Prepare a sample input for testing (using the first test example from `X_test`)
sample_input = X_test[0:1].astype(np.float32)  # Select one test example and convert it to float32 (required by ONNX)

# Run inference (make a prediction) using the ONNX model
input_name = session.get_inputs()[0].name  # Get the input name for the ONNX model
output_name = session.get_outputs()[0].name  # Get the output name for the ONNX model
result = session.run([output_name], {input_name: sample_input})  # Run inference

# Print the predicted result
print("Predicted class (from ONNX model):", result[0][0])  # Output the predicted class (0, 1, or 2)

print("ONNX model inference completed successfully!")